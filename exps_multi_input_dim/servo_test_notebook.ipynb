{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import numpy.linalg as linalg\n",
    "\n",
    "import spectralgp\n",
    "\n",
    "from spectralgp.samplers import AlternatingSampler\n",
    "from spectralgp.models import ExactGPModel, SpectralModel, ProductKernelSpectralModel\n",
    "\n",
    "from spectralgp.sampling_factories import ss_factory, ess_factory\n",
    "from custom_plotting import plot_kernel\n",
    "\n",
    "import data\n",
    "\n",
    "import utils\n",
    "import argparse\n",
    "\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import traceback\n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available True\n",
      "Input Dimensions 4\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, test_x, test_y, y_std, y_std_train, gen_kern = data.read_data('servo', nx=None, gen_pars=None,\n",
    "                                                            linear_pars=None,\n",
    "                                                            spacing='random',\n",
    "                                                            noise=None)\n",
    "in_dims = 1 if train_x.dim() == 1 else train_x.size(1)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('Cuda is available', use_cuda)\n",
    "if use_cuda:\n",
    "    torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "    train_x, train_y, test_x, test_y, y_std = train_x.cuda(), train_y.cuda(), test_x.cuda(), test_y.cuda(), y_std.cuda()\n",
    "    if gen_kern is not None:\n",
    "        gen_kern = gen_kern.cuda()\n",
    "\n",
    "###########################################\n",
    "## set up the spectral and latent models ##\n",
    "###########################################\n",
    "print(\"Input Dimensions {}\".format(in_dims))\n",
    "\n",
    "\n",
    "\n",
    "mlatent = 'shared'\n",
    "shared = True if mlatent == 'shared' else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(8.)\n",
      "0\n",
      "tensor(8.)\n",
      "0\n",
      "tensor(8.)\n"
     ]
    }
   ],
   "source": [
    "data_lh = gpytorch.likelihoods.GaussianLikelihood(noise_prior=gpytorch.priors.SmoothedBoxPrior(1e-8, 1e-3))\n",
    "data_mod = spectralgp.models.ProductKernelSpectralModel(train_x, train_y, data_lh, shared=shared,\n",
    "        normalize = False, symmetrize = False, num_locs = 100, spacing='random', pretrain=False, omega_max = 8., nonstat = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 Dimension:  0\n",
      "Loss is:  tensor(-85.7762, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-84.6493, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-83.4721, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-82.3135, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-81.2497, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 0\n",
      "Step:  0 Dimension:  1\n",
      "Loss is:  tensor(-79.1902, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-78.1038, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-77.0373, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-75.9855, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-74.9398, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 0\n",
      "Step:  0 Dimension:  2\n",
      "Loss is:  tensor(-74.2700, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-73.2337, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-72.2256, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-71.2269, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-70.2589, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 0\n",
      "Step:  0 Dimension:  3\n",
      "Loss is:  tensor(-69.1745, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-68.2150, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-67.2831, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-66.3597, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-65.4270, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 0\n",
      "Seconds for Iteration 0 : 5.54294228553772\n",
      "Step:  1 Dimension:  0\n",
      "Loss is:  tensor(-64.5697, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-63.6520, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-62.7844, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-61.9106, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-61.0549, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 1\n",
      "Step:  1 Dimension:  1\n",
      "Loss is:  tensor(-59.9664, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-59.1319, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-58.3036, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-57.4877, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-56.6721, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 1\n",
      "Step:  1 Dimension:  2\n",
      "Loss is:  tensor(-55.7953, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-55.0214, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-54.2442, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-53.4836, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-52.7217, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 1\n",
      "Step:  1 Dimension:  3\n",
      "Loss is:  tensor(-51.9540, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-51.2197, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-50.4916, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-49.7873, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-49.0790, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 1\n",
      "Seconds for Iteration 1 : 5.8860907554626465\n",
      "Step:  2 Dimension:  0\n",
      "Loss is:  tensor(-48.4859, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-47.7997, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-47.1170, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-46.4563, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-45.8085, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 2\n",
      "Step:  2 Dimension:  1\n",
      "Loss is:  tensor(-45.1980, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-44.5727, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-43.9371, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-43.3115, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-42.7111, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 2\n",
      "Step:  2 Dimension:  2\n",
      "Loss is:  tensor(-42.1975, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-41.6063, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-41.0160, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-40.4464, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-39.8811, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 2\n",
      "Step:  2 Dimension:  3\n",
      "Loss is:  tensor(-39.1630, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-38.5970, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-38.0764, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-37.5343, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-36.9949, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 2\n",
      "Seconds for Iteration 2 : 5.80753231048584\n",
      "Step:  3 Dimension:  0\n",
      "Loss is:  tensor(-36.3888, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-35.8788, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-35.3756, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-34.8674, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-34.3853, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 3\n",
      "Step:  3 Dimension:  1\n",
      "Loss is:  tensor(-33.9659, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-33.5072, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-33.0273, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-32.5612, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-32.1153, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 3\n",
      "Step:  3 Dimension:  2\n",
      "Loss is:  tensor(-31.6305, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-31.1851, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-30.7519, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-30.3252, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-29.9008, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 3\n",
      "Step:  3 Dimension:  3\n",
      "Loss is:  tensor(-29.5286, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-29.0996, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-28.6977, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-28.3044, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-27.9113, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 3\n",
      "Seconds for Iteration 3 : 5.890558481216431\n",
      "Step:  4 Dimension:  0\n",
      "Loss is:  tensor(-27.6600, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-27.2835, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-26.8981, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-26.5428, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-26.1715, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 4\n",
      "Step:  4 Dimension:  1\n",
      "Loss is:  tensor(-25.6717, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-25.3077, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-24.9639, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-24.6244, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-24.2899, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 4\n",
      "Step:  4 Dimension:  2\n",
      "Loss is:  tensor(-23.9398, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-23.6063, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-23.2845, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-22.9691, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-22.6696, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 4\n",
      "Step:  4 Dimension:  3\n",
      "Loss is:  tensor(-22.4267, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-22.1345, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-21.8246, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-21.5386, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-21.2536, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 4\n",
      "Seconds for Iteration 4 : 6.276173114776611\n",
      "Step:  5 Dimension:  0\n",
      "Loss is:  tensor(-21.1080, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-20.8242, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-20.5544, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-20.2736, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-20.0077, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 5\n",
      "Step:  5 Dimension:  1\n",
      "Loss is:  tensor(-19.7302, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-19.4864, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-19.2236, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-18.9711, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-18.7345, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 5\n",
      "Step:  5 Dimension:  2\n",
      "Loss is:  tensor(-18.3616, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-18.1378, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-17.8976, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-17.6442, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-17.4379, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 5\n",
      "Step:  5 Dimension:  3\n",
      "Loss is:  tensor(-17.2113, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-16.9896, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-16.7788, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-16.5653, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-16.3567, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 5\n",
      "Seconds for Iteration 5 : 6.299560546875\n",
      "Step:  6 Dimension:  0\n",
      "Loss is:  tensor(-15.8945, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-15.6918, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-15.5022, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-15.2990, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-15.1109, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 6\n",
      "Step:  6 Dimension:  1\n",
      "Loss is:  tensor(-14.8958, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-14.7029, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-14.5123, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-14.3599, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-14.1626, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 6\n",
      "Step:  6 Dimension:  2\n",
      "Loss is:  tensor(-14.0275, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-13.8567, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-13.6697, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:  tensor(-13.5035, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-13.3490, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 6\n",
      "Step:  6 Dimension:  3\n",
      "Loss is:  tensor(-13.1246, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-12.9722, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-12.8194, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-12.6682, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-12.5095, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 6\n",
      "Seconds for Iteration 6 : 6.434166431427002\n",
      "Step:  7 Dimension:  0\n",
      "Loss is:  tensor(-12.3678, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-12.2345, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-12.0870, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-11.9513, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-11.8056, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 7\n",
      "Step:  7 Dimension:  1\n",
      "Loss is:  tensor(-11.5880, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-11.4542, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-11.3296, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-11.1933, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-11.0637, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 7\n",
      "Step:  7 Dimension:  2\n",
      "Loss is:  tensor(-10.9396, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-10.8110, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-10.6852, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-10.5673, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-10.4565, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 7\n",
      "Step:  7 Dimension:  3\n",
      "Loss is:  tensor(-10.2414, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-10.1358, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-10.0321, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-9.9118, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-9.8249, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 7\n",
      "Seconds for Iteration 7 : 6.380223035812378\n",
      "Step:  8 Dimension:  0\n",
      "Loss is:  tensor(-9.6572, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-9.5487, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-9.4729, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-9.3584, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-9.2596, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 8\n",
      "Step:  8 Dimension:  1\n",
      "Loss is:  tensor(-9.1473, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-9.0621, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-8.9708, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-8.8638, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-8.7901, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 8\n",
      "Step:  8 Dimension:  2\n",
      "Loss is:  tensor(-8.6609, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-8.5596, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-8.4706, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-8.3936, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-8.3198, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 8\n",
      "Step:  8 Dimension:  3\n",
      "Loss is:  tensor(-8.2517, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-8.1749, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-8.0943, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-8.0032, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-7.9501, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 8\n",
      "Seconds for Iteration 8 : 6.140540361404419\n",
      "Step:  9 Dimension:  0\n",
      "Loss is:  tensor(-7.7815, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-7.6869, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-7.6036, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-7.5556, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-7.4904, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 9\n",
      "Step:  9 Dimension:  1\n",
      "Loss is:  tensor(-7.3384, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-7.2813, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-7.1960, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-7.1261, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-7.0764, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 9\n",
      "Step:  9 Dimension:  2\n",
      "Loss is:  tensor(-7.0506, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-6.9973, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-6.9427, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-6.8954, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-6.8254, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 9\n",
      "Step:  9 Dimension:  3\n",
      "Loss is:  tensor(-6.7470, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-6.6856, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-6.6355, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-6.5795, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-6.5364, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 9\n",
      "Seconds for Iteration 9 : 6.714493989944458\n"
     ]
    }
   ],
   "source": [
    "alt_sampler = spectralgp.samplers.AlternatingSampler(\n",
    "    [data_mod], [data_lh], \n",
    "    spectralgp.sampling_factories.ss_factory, [spectralgp.sampling_factories.ess_factory],\n",
    "    totalSamples=10, numInnerSamples=5, numOuterSamples=5, num_dims=in_dims\n",
    "    )\n",
    "\n",
    "\n",
    "alt_sampler.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1556653114079/work/aten/src/THC/generic/THCTensorMathPointwise.cu:46",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b035d6db1782>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malt_sampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/spectralgp_prod/spectralgp/exps_multi_input_dim/custom_plotting.py\u001b[0m in \u001b[0;36mplot_kernel\u001b[0;34m(alt_sampler, data_mod, gen_kern)\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mout_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt_sampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgsampled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlast_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mdata_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovar_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_latent_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0mplt_kernels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcovar_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mplt_kernels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt_kernels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/gpytorch/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36msqueeze\u001b[0;34m(self, dim)\u001b[0m\n\u001b[1;32m   1425\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1427\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/gpytorch/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m   1695\u001b[0m         \u001b[0;31m# with the appropriate shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msqueeze_row\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msqueeze_col\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mrow_col_are_absorbed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1697\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelazify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1698\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msqueeze_row\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/gpytorch/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36mdelazify\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1745\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1747\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"object of class {} cannot be made into a Tensor\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/gpytorch/gpytorch/utils/memoize.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mcache_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_in_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0madd_to_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/gpytorch/gpytorch/utils/memoize.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mcache_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_in_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0madd_to_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/gpytorch/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\u001b[0m in \u001b[0;36mevaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             res = self.kernel(\n\u001b[0;32m--> 270\u001b[0;31m                 \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             )\n\u001b[1;32m    272\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_active_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/gpytorch/gpytorch/kernels/kernel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLazyEvaluatedKernelTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/gpytorch/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/spectralgp_prod/spectralgp/spectralgp/kernels/spectral_gp_kernel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m# transform to enforce positivity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mdensity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymmetrize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1556653114079/work/aten/src/THC/generic/THCTensorMathPointwise.cu:46"
     ]
    }
   ],
   "source": [
    "plot_kernel(alt_sampler, data_mod, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spectralgp] *",
   "language": "python",
   "name": "conda-env-spectralgp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
