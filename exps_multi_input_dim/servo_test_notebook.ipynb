{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import numpy.linalg as linalg\n",
    "\n",
    "import spectralgp\n",
    "\n",
    "from spectralgp.samplers import AlternatingSampler\n",
    "from spectralgp.models import ExactGPModel, SpectralModel, ProductKernelSpectralModel\n",
    "\n",
    "from spectralgp.sampling_factories import ss_factory, ess_factory\n",
    "from custom_plotting import plot_kernel\n",
    "\n",
    "import data\n",
    "\n",
    "import utils\n",
    "import argparse\n",
    "\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import traceback\n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available True\n",
      "Input Dimensions 4\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, test_x, test_y, y_std, y_std_train, gen_kern = data.read_data('servo', nx=None, gen_pars=None,\n",
    "                                                            linear_pars=None,\n",
    "                                                            spacing='random',\n",
    "                                                            noise=None)\n",
    "in_dims = 1 if train_x.dim() == 1 else train_x.size(1)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('Cuda is available', use_cuda)\n",
    "if use_cuda:\n",
    "    torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "    train_x, train_y, test_x, test_y, y_std = train_x.cuda(), train_y.cuda(), test_x.cuda(), test_y.cuda(), y_std.cuda()\n",
    "    if gen_kern is not None:\n",
    "        gen_kern = gen_kern.cuda()\n",
    "\n",
    "###########################################\n",
    "## set up the spectral and latent models ##\n",
    "###########################################\n",
    "print(\"Input Dimensions {}\".format(in_dims))\n",
    "\n",
    "\n",
    "\n",
    "mlatent = 'shared'\n",
    "shared = True if mlatent == 'shared' else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(8.)\n",
      "0\n",
      "tensor(8.)\n",
      "0\n",
      "tensor(8.)\n"
     ]
    }
   ],
   "source": [
    "data_lh = gpytorch.likelihoods.GaussianLikelihood(noise_prior=gpytorch.priors.SmoothedBoxPrior(1e-8, 1e-3))\n",
    "data_mod = spectralgp.models.ProductKernelSpectralModel(train_x, train_y, data_lh, shared=shared,\n",
    "        normalize = False, symmetrize = False, num_locs = 100, spacing='random', pretrain=False, omega_max = 8., nonstat = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  0 Dimension:  0\n",
      "Loss is:  tensor(-84.4658, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-83.2822, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-82.1321, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-80.9971, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-79.9002, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 0\n",
      "Step:  0 Dimension:  1\n",
      "Loss is:  tensor(-79.4123, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-78.3284, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-77.2648, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-76.2081, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-75.1706, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 0\n",
      "Step:  0 Dimension:  2\n",
      "Loss is:  tensor(-74.0962, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-73.0765, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-72.0711, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-71.0838, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-70.1122, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 0\n",
      "Step:  0 Dimension:  3\n",
      "Loss is:  tensor(-69.1951, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-68.2495, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-67.2985, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-66.3726, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-65.4630, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 0\n",
      "Seconds for Iteration 0 : 4.711709260940552\n",
      "Step:  1 Dimension:  0\n",
      "Loss is:  tensor(-64.7409, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-63.8428, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-62.9723, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-62.1077, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-61.2414, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 1\n",
      "Step:  1 Dimension:  1\n",
      "Loss is:  tensor(-60.1640, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-59.3348, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-58.4942, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-57.6831, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-56.8769, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 1\n",
      "Step:  1 Dimension:  2\n",
      "Loss is:  tensor(-56.1671, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-55.3950, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-54.6223, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-53.8586, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-53.1129, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 1\n",
      "Step:  1 Dimension:  3\n",
      "Loss is:  tensor(-52.3323, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-51.5767, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-50.8572, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-50.1505, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-49.4597, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 1\n",
      "Seconds for Iteration 1 : 5.462945938110352\n",
      "Step:  2 Dimension:  0\n",
      "Loss is:  tensor(-48.8976, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-48.2135, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-47.5454, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-46.8672, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-46.2260, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 2\n",
      "Step:  2 Dimension:  1\n",
      "Loss is:  tensor(-45.4371, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-44.8020, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-44.1743, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-43.5582, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-42.9451, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 2\n",
      "Step:  2 Dimension:  2\n",
      "Loss is:  tensor(-42.2182, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-41.6084, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-41.0175, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-40.4472, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-39.8788, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 2\n",
      "Step:  2 Dimension:  3\n",
      "Loss is:  tensor(-39.7078, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-39.1382, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-38.5990, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-38.0612, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-37.5294, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 2\n",
      "Seconds for Iteration 2 : 5.056065559387207\n",
      "Step:  3 Dimension:  0\n",
      "Loss is:  tensor(-36.9444, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-36.4285, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-35.9322, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-35.4234, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-34.9332, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 3\n",
      "Step:  3 Dimension:  1\n",
      "Loss is:  tensor(-34.1580, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-33.6730, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-33.1883, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-32.7187, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-32.2746, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 3\n",
      "Step:  3 Dimension:  2\n",
      "Loss is:  tensor(-31.5699, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-31.1270, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-30.6772, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-30.2465, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-29.8252, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 3\n",
      "Step:  3 Dimension:  3\n",
      "Loss is:  tensor(-29.3547, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-28.9297, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-28.5259, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-28.1273, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-27.7337, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 3\n",
      "Seconds for Iteration 3 : 5.735767841339111\n",
      "Step:  4 Dimension:  0\n",
      "Loss is:  tensor(-27.0799, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-26.6911, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-26.3044, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-25.9408, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-25.5711, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 4\n",
      "Step:  4 Dimension:  1\n",
      "Loss is:  tensor(-25.3347, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-24.9723, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-24.6315, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-24.2919, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-23.9410, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 4\n",
      "Step:  4 Dimension:  2\n",
      "Loss is:  tensor(-23.7146, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-23.3642, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-23.0488, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-22.7328, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-22.4124, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 4\n",
      "Step:  4 Dimension:  3\n",
      "Loss is:  tensor(-22.4366, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-22.1548, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-21.8496, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-21.5546, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-21.2497, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 4\n",
      "Seconds for Iteration 4 : 5.069181442260742\n",
      "Step:  5 Dimension:  0\n",
      "Loss is:  tensor(-20.8758, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-20.5967, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-20.3287, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-20.0386, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-19.7789, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 5\n",
      "Step:  5 Dimension:  1\n",
      "Loss is:  tensor(-19.7109, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-19.4532, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-19.1976, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-18.9471, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-18.7039, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 5\n",
      "Step:  5 Dimension:  2\n",
      "Loss is:  tensor(-18.3987, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-18.1712, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-17.9423, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-17.7109, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-17.4808, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 5\n",
      "Step:  5 Dimension:  3\n",
      "Loss is:  tensor(-17.2723, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-17.0504, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-16.8372, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-16.6169, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-16.4015, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 5\n",
      "Seconds for Iteration 5 : 5.280515670776367\n",
      "Step:  6 Dimension:  0\n",
      "Loss is:  tensor(-16.1846, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-15.9610, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-15.7659, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-15.5702, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-15.3799, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 6\n",
      "Step:  6 Dimension:  1\n",
      "Loss is:  tensor(-15.1140, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-14.9592, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-14.7485, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-14.5723, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-14.4041, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 6\n",
      "Step:  6 Dimension:  2\n",
      "Loss is:  tensor(-14.1615, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-13.9952, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-13.8267, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:  tensor(-13.6643, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-13.5082, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 6\n",
      "Step:  6 Dimension:  3\n",
      "Loss is:  tensor(-13.2398, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-13.0606, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-12.9192, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-12.7689, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-12.6050, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 6\n",
      "Seconds for Iteration 6 : 4.846317768096924\n",
      "Step:  7 Dimension:  0\n",
      "Loss is:  tensor(-12.3334, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-12.1776, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-12.0223, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-11.8702, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-11.7462, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 7\n",
      "Step:  7 Dimension:  1\n",
      "Loss is:  tensor(-11.8561, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-11.6807, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-11.5546, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-11.4129, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-11.2778, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 7\n",
      "Step:  7 Dimension:  2\n",
      "Loss is:  tensor(-11.1853, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-11.0253, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-10.9152, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-10.7950, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-10.6987, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 7\n",
      "Step:  7 Dimension:  3\n",
      "Loss is:  tensor(-10.7833, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-10.6493, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-10.5357, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-10.4245, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-10.3103, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 7\n",
      "Seconds for Iteration 7 : 4.939686059951782\n",
      "Step:  8 Dimension:  0\n",
      "Loss is:  tensor(-10.3940, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-10.2645, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-10.1580, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-10.0568, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-9.9734, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 8\n",
      "Step:  8 Dimension:  1\n",
      "Loss is:  tensor(-9.7676, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-9.6701, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-9.5659, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-9.4846, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-9.4025, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 8\n",
      "Step:  8 Dimension:  2\n",
      "Loss is:  tensor(-9.3107, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-9.2093, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-9.1271, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-9.0295, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-8.9660, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 8\n",
      "Step:  8 Dimension:  3\n",
      "Loss is:  tensor(-8.7141, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-8.6276, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-8.5433, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-8.4567, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-8.4011, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 8\n",
      "Seconds for Iteration 8 : 5.6615283489227295\n",
      "Step:  9 Dimension:  0\n",
      "Loss is:  tensor(-8.2583, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-8.1637, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-8.0983, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-8.0153, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-7.9527, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 9\n",
      "Step:  9 Dimension:  1\n",
      "Loss is:  tensor(-7.9114, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-7.8485, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-7.7882, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-7.7310, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-7.6591, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 9\n",
      "Step:  9 Dimension:  2\n",
      "Loss is:  tensor(-7.4079, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-7.3312, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-7.2886, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-7.2054, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-7.1556, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 9\n",
      "Step:  9 Dimension:  3\n",
      "Loss is:  tensor(-7.1213, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-7.0469, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-6.9812, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-6.9451, grad_fn=<DivBackward0>)\n",
      "Loss is:  tensor(-6.8914, grad_fn=<DivBackward0>)\n",
      "Task: 0 ; Iteration 9\n",
      "Seconds for Iteration 9 : 5.647614479064941\n"
     ]
    }
   ],
   "source": [
    "alt_sampler = spectralgp.samplers.AlternatingSampler(\n",
    "    [data_mod], [data_lh], \n",
    "    spectralgp.sampling_factories.ss_factory, [spectralgp.sampling_factories.ess_factory],\n",
    "    totalSamples=10, numInnerSamples=10, numOuterSamples=5, num_dims=in_dims\n",
    "    )\n",
    "\n",
    "\n",
    "alt_sampler.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalised RMSE: 0.20234513950116603\n",
      "Unnormalised RMSE: 0.18199989698079141\n",
      "Summed NLL: 3.8151302280576425\n",
      "MSLL: -1.3795751601879567\n"
     ]
    }
   ],
   "source": [
    "data_mod.eval()\n",
    "data_lh.eval()\n",
    "\n",
    "data_mod_means = torch.zeros_like(data_mod(test_x).mean)\n",
    "total_variance = torch.zeros_like(data_lh(data_mod(test_x)).variance)\n",
    "\n",
    "test_rmse = 0.0\n",
    "unnorm_test_rmse = 0.0\n",
    "nll_sum = 0.0\n",
    "msll = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    marg_samples_num = min(len(alt_sampler.fhsampled[0][0]), alt_sampler.fgsampled[0].shape[-1])\n",
    "    \n",
    "    for x in range(0, marg_samples_num):\n",
    "        # This line must come first\n",
    "        data_mod.load_state_dict(alt_sampler.fhsampled[0][0][x]) # dim, ???, nsample\n",
    "        \n",
    "        for dim in range(0,in_dims):\n",
    "            data_mod.covar_module.set_latent_params(alt_sampler.fgsampled[dim][0, :, x], idx=dim)\n",
    "            \n",
    "        # Verify this is the correct way to handle multidim train setting\n",
    "\n",
    "        data_mod.set_train_data(train_x, train_y) # to clear out the cache\n",
    "        data_mod_means += data_mod(test_x).mean\n",
    "\n",
    "        y_preds = data_lh(data_mod(test_x))\n",
    "        # y_var = f_var + data_noise\n",
    "        y_var = y_preds.variance\n",
    "        total_variance += (y_var + torch.pow(data_mod(test_x).mean,2))\n",
    "\n",
    "\n",
    "meaned_data_mod_means = data_mod_means / float(marg_samples_num)\n",
    "total_variance = total_variance/float(marg_samples_num) - torch.pow(meaned_data_mod_means,2)\n",
    "\n",
    "d = meaned_data_mod_means - test_y\n",
    "du = d * y_std\n",
    "\n",
    "test_rmse = torch.sqrt(torch.mean(torch.pow(d, 2)))\n",
    "unnorm_test_rmse = torch.sqrt(torch.mean(torch.pow(du, 2)))\n",
    "\n",
    "nll = 0.5 * torch.log(2. * math.pi * total_variance) +  torch.pow((meaned_data_mod_means - test_y),2)/(2. * total_variance)\n",
    "sll = nll - (0.5 * torch.log(2. * math.pi * torch.pow(y_std_train, 2)) +  torch.pow((torch.mean(train_y) - test_y),2)/(2. * torch.pow(y_std_train, 2)))\n",
    "msll += torch.mean(sll)\n",
    "nll_sum += nll.sum()\n",
    "\n",
    "print(\"Normalised RMSE: {}\".format(test_rmse))\n",
    "print(\"Unnormalised RMSE: {}\".format(unnorm_test_rmse))\n",
    "print(\"Summed NLL: {}\".format(nll_sum))\n",
    "print(\"MSLL: {}\".format(msll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jayson_s/anaconda3/envs/spectralgp/lib/python3.7/site-packages/matplotlib-3.0.3-py3.7-linux-x86_64.egg/matplotlib/axes/_base.py:380: MatplotlibDeprecationWarning: \n",
      "cycling among columns of inputs with non-matching shapes is deprecated.\n",
      "  cbook.warn_deprecated(\"2.2\", \"cycling among columns of inputs \"\n"
     ]
    }
   ],
   "source": [
    "plot_kernel(alt_sampler, data_mod, 'servo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spectralgp] *",
   "language": "python",
   "name": "conda-env-spectralgp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
